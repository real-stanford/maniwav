name: umi_maniwav
dataset_path: ''

camera_obs_latency: 0.125
# need to figure out audio_obs_latency if is matters
robot_obs_latency: 0.0001
gripper_obs_latency: 0.02
dataset_frequeny: 0 #59.94
obs_down_sample_steps: 3 # 3, 1

low_dim_obs_horizon: 2
audio_obs_horizon: 120
img_obs_horizon: 2
action_horizon: 16

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    camera0_rgb:
      shape: [3, 224, 224]
      horizon: ${task.img_obs_horizon} # int
      latency_steps: 0 # float
      down_sample_steps: ${task.obs_down_sample_steps} # int
      type: rgb
    mic_0:
      shape: [800]
      horizon: ${task.audio_obs_horizon}
      latency_steps: 0 # float
      down_sample_steps: 1 # audio becomes broken if this is 3
      type: audio
      aug:
        - _target_: diffusion_policy.model.common.noise_aug.NoiseAug
          noise_folder_path: data/esc-50
          p: 0.5
        - _target_: diffusion_policy.model.common.noise_aug.RobotNoiseAug
          noise_path: data/robot-noise-calib/robot.wav
          key: 'mic_0'
          p: 0.5
    # mic_1:
    #   shape: [800]
    #   horizon: ${task.audio_obs_horizon}
    #   latency_steps: 0 # float
    #   down_sample_steps: 1
    #   type: audio
    robot0_eef_pos:
      shape: [3]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim
    # robot0_eef_pos_abs:
    #   shape: [1]
    #   axis: [2] # 2 means z-axis
    #   horizon: ${task.low_dim_obs_horizon} # int
    #   latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
    #   down_sample_steps: ${task.obs_down_sample_steps} # float
    #   type: low_dim
    # robot0_eef_rot_axis_angle_abs:
    #   shape: [2]
    #   axis: [0, 1] # yaw and pitch
    #   horizon: ${task.low_dim_obs_horizon} # int
    #   latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
    #   down_sample_steps: ${task.obs_down_sample_steps} # float
    #   type: low_dim
    robot0_eef_rot_axis_angle:
      raw_shape: [3]
      shape: [6]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.robot_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim
      rotation_rep: rotation_6d
    robot0_gripper_width:
      shape: [1]
      horizon: ${task.low_dim_obs_horizon} # int
      latency_steps: ${eval:'(${task.camera_obs_latency} - ${task.gripper_obs_latency}) * ${task.dataset_frequeny}'} # float
      down_sample_steps: ${task.obs_down_sample_steps} # float
      type: low_dim
  action: 
    shape: [10]
    horizon: ${task.action_horizon}
    latency_steps: 0 # float
    down_sample_steps: ${task.obs_down_sample_steps} # int
    rotation_rep: rotation_6d

task_name: &task_name umi_maniwav
pose_repr: &pose_repr
  # relative is the correct implementation, not abs nor rel
  obs_pose_repr: relative # abs or rel
  action_pose_repr: relative # absrobot0_eef_rot_axis_angle or rel or delta

env_runner:
  _target_: diffusion_policy.env_runner.real_pusht_image_runner.RealPushTImageRunner

dataset:
  _target_: diffusion_policy.dataset.umi_maniwav_dataset.UmiManiWAVDataset
  shape_meta: *shape_meta
  dataset_path: ${task.dataset_path}
  # val_dataset_path: ${task.val_dataset_path}
  cache_dir: null
  pose_repr: *pose_repr
  action_padding: False
  temporally_independent_normalization: False
  repeat_frame_prob: 0.0
  seed: 42
  val_ratio: 0.05
